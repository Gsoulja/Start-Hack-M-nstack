# Start-Hack-M-nstack
Model preparation and deploy  for the hackthon

# Domain Adaptation Model API

A lightweight API service for domain-adapted language models that preserves natural language capabilities while adding domain-specific knowledge.

## ğŸŒŸ Features

- **Domain Adaptation**: Fine-tune pre-trained language models on specific domains while preserving general language abilities
- **Simple API**: Easy-to-use FastAPI service with clear endpoints
- **Production-Ready**: Detailed deployment guides for VPS with Nginx/Apache
- **Modular Design**: Easily extensible codebase for hackathons and projects

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- PyTorch 1.9+
- CUDA (optional, for GPU acceleration)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/domain-adaptation-api.git
cd domain-adaptation-api

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Running the API Server (Development)

```bash
# Start the API server
uvicorn api.simple_api:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at http://localhost:8000. You can access the automatic documentation at http://localhost:8000/docs.

### Training a Domain-Adapted Model

```bash
# Run the training script with your domain data
python scripts/train_model.py --domain medical --data data/medical_texts.csv --epochs 5
```

## ğŸ“š API Usage

### Load a Model

```bash
curl -X POST "http://localhost:8000/load-model" \
  -H "Content-Type: application/json" \
  -d '{"model_path": "models/medical_20250316_123456"}'
```

### Predict Masked Tokens

```bash
curl -X POST "http://localhost:8000/predict-mask" \
  -H "Content-Type: application/json" \
  -d '{"text": "The patient'"'"'s [MASK] showed signs of myocardial infarction.", "k": 5}'
```

## ğŸ“‹ Project Structure

```
domain-adaptation-api/
â”œâ”€â”€ api/                   # API code
â”‚   â”œâ”€â”€ simple_api.py      # Simple API implementation
â”‚   â”œâ”€â”€ routers/           # API routers (advanced version)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                # Directory for saved models
â”œâ”€â”€ scripts/               # Training and utility scripts
â”‚   â”œâ”€â”€ train_model.py     # Domain adaptation training script
â”‚   â””â”€â”€ ...
â”œâ”€â”€ deploy/                # Deployment configurations
â”‚   â”œâ”€â”€ nginx/             # Nginx configuration
â”‚   â”œâ”€â”€ apache/            # Apache configuration
â”‚   â””â”€â”€ systemd/           # Systemd service files
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ deployment.md      # Deployment guide
â”‚   â””â”€â”€ api.md             # API reference
â””â”€â”€ requirements.txt       # Project dependencies
```

## ğŸ”§ Deployment

See [Deployment Guide](docs/deployment.md) for detailed instructions on deploying this API service to production using:

- VPS (DigitalOcean, AWS EC2, etc.)
- Nginx as a reverse proxy
- Apache as an alternative to Nginx
- Systemd for process management
- SSL/TLS configuration

## ğŸ“Š Performance Considerations

- For optimal performance, use a machine with a GPU.
- Model loading takes significant memory - adjust batch sizes according to your hardware.
- Consider using a smaller model for faster inference on limited hardware.

## ğŸ”— Related Projects

- [PEFT](https://github.com/huggingface/peft) - Parameter-Efficient Fine-Tuning methods
- [Hugging Face Transformers](https://github.com/huggingface/transformers) - State-of-the-art Natural Language Processing

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgements

- Hugging Face for the Transformers library
- FastAPI for the web framework
